
Now you have a model entry with the correct configuration. Let's extract it.

#### 1. List Models to Find the New Name
Run `ollama list` to see all installed models. You should see your temporary model (`qwen3-temp:latest`) and the new one with the long Hugging Face name.

```bash
ollama list
```
| NAME | ID | SIZE | MODIFIED |
| :--- | :--- | :--- | :--- |
| `qwen3-temp:latest` | `a1b2c3d4e5f6` | `4.8 GB` | `1 minute ago` |
| `hf.co/unsloth/Deep...:Q4_K_M` | `a1b2c3d4e5f6` | `4.8 GB` | `30 seconds ago` |

#### 2. Export the Official Modelfile
Use `ollama show --modelfile` with the long model name to export its configuration to a new file. This will be your "perfect" `Modelfile`.

```bash
ollama show --modelfile hf.co/unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF:Q4_K_M > /path/to/your/perfect-qwen3-modelfile
```

#### 3. Update the `FROM` Path
Open the newly created `perfect-qwen3-modelfile`. The `FROM` line will point to a blob hash in Ollama's internal storage. **You must change this back to the path of your original GGUF file.**

```bash
nvim /path/to/your/perfect-qwen3-modelfile
```

**Before:**
```modelfile
# Modelfile generated by "ollama show"
FROM /home/user/.ollama/models/blobs/sha256:a1b2c3d4e5f6...
TEMPLATE """{{- if .System }}..."""
PARAMETER stop "<|im_end|>"
# ... and other parameters
```

**After:**
```modelfile
# Modelfile generated by "ollama show"
FROM /mnt/media/Documents/Lmstudiodownlaods/qwen3_Q4_K_S.gguf
TEMPLATE """{{- if .System }}..."""
PARAMETER stop "<|im_end|>"
# ... and other parameters
```